using Emgu.CV;
using Emgu.CV.Structure;
using Emgu.CV.Shape;
using Emgu.CV.CvEnum;
using Emgu.CV.Aruco;
using Emgu.CV.Util;
using Emgu.CV.XImgproc;
using Emgu.CV.Cuda;

using Microsoft.Win32;
using System;
using System.Diagnostics;
using System.Windows;
using System.Windows.Media.Imaging;
using System.Drawing;
using System.Collections.Generic;
using System.Drawing.Configuration;
using PointConverter = System.Drawing.PointConverter;
using Microsoft.VisualBasic;
using System.Windows.Controls;
using System.IO;
using System.Drawing.Imaging;
using System.Linq;
using System.Runtime.InteropServices;
using System.Text;
using System.Xml.Serialization;
using System.Xml;
using System.ComponentModel;
using Point = System.Drawing.Point;
using Emgu.CV.Features2D;
using System.Windows.Media.Media3D;

namespace SampleOpenCV
{
    public static class MatExtension
    {
        public static dynamic GetValue(this Mat mat, int row, int col)
        {
            var value = CreateElement(mat.Depth);
            Marshal.Copy(mat.DataPointer + (row * mat.Cols + col) * mat.ElementSize, value, 0, 1);
            return value[0];
        }

        public static void SetValue(this Mat mat, int row, int col, dynamic value)
        {
            var target = CreateElement(mat.Depth, value);
            Marshal.Copy(target, 0, mat.DataPointer + (row * mat.Cols + col) * mat.ElementSize, 1);
        }
        private static dynamic CreateElement(DepthType depthType, dynamic value)
        {
            var element = CreateElement(depthType);
            element[0] = value;
            return element;
        }

        private static dynamic CreateElement(DepthType depthType)
        {
            if (depthType == DepthType.Cv8S)
            {
                return new sbyte[1];
            }
            if (depthType == DepthType.Cv8U)
            {
                return new byte[1];
            }
            if (depthType == DepthType.Cv16S)
            {
                return new short[1];
            }
            if (depthType == DepthType.Cv16U)
            {
                return new ushort[1];
            }
            if (depthType == DepthType.Cv32S)
            {
                return new int[1];
            }
            if (depthType == DepthType.Cv32F)
            {
                return new float[1];
            }
            if (depthType == DepthType.Cv64F)
            {
                return new double[1];
            }
            return new float[1];
        }
    }

    /// <summary>
    /// Interaction logic for MainWindow.xaml
    /// </summary>
    public partial class MainWindow : Window
    {
        //[System.Runtime.InteropServices.DllImport("gdi32.dll")]
        Matrix<double> cameraMatrix = new Matrix<double>(3, 3);
        Matrix<double> distortionMatrix = new Matrix<double>(5, 1);
        Matrix<double> cameraMatrix2 = new Matrix<double>(3, 3);
        Matrix<double> distortionMatrix2 = new Matrix<double>(5, 1);
        Matrix<double> homographyMatrix = new Matrix<double>(3, 3);
        Matrix<double> invHomographyMatrix = new Matrix<double>(3, 3);
        List<float[,]> lineConvMats = new List<float[,]>();

        //Mat cameraMatrixMat = new Mat(3, 3, DepthType.Cv64F, 1);
        //Mat distortionMatrixMat = new Mat(5, 1, DepthType.Cv64F, 1);

        public MainWindow()
        {
            InitializeComponent();
            Title = "MainWindow - No File Opened";

            /*  Examples
             
            if (homographyMatrix != null)
            {
                XmlReader rdr = XmlReader.Create(new StringReader(properties.SampleOpenCV.Default.HomographyMatrix));
                if (rdr != null)
                {
                    object o = (new XmlSerializer(typeof(Matrix<double>))).Deserialize(rdr);
                    if (o != null)
                    {
                        homographyMatrix = (Matrix<double>)o;
                        invHomographyMatrix = new Matrix<double>(3, 3);
                        CvInvoke.Invert(homographyMatrix, invHomographyMatrix, DecompMethod.LU);
                    }
                }
            }

            Image<Gray, float> distImage = new Image<Gray, float>(new float[,,] { 
                { { 1 }, { 2 }, { 3 } },
                { { 4 }, { 5 }, { 6 } },
                { { 7 }, { 8 }, { 9 } }
            });

            invHomographyMatrix = new Matrix<double>(3, 3);
            CvInvoke.Invert (homographyMatrix, invHomographyMatrix, DecompMethod.LU);

            Mat distMat = distImage.Mat;
            Mat coordMat = new Mat(1, 3, DepthType.Cv64F, 1);

            Matrix<double> myCoord = new Matrix<double>(new double[,] { { 1200, 1300, 0 } });
            Matrix<double> myResult = myCoord * homographyMatrix;
            Matrix<double> myRevResult = myResult * invHomographyMatrix;

            myCoord[0,0] = 1.0;
            */

            /*
            byte[] b000 = FileToByteArray("C:\\Users\\Gerhard J Norkus\\source\\repos\\SampleOpenCV\\Calibration5Images\\SampleMetalShots\\rot000.data");
            byte[] b011 = FileToByteArray("C:\\Users\\Gerhard J Norkus\\source\\repos\\SampleOpenCV\\Calibration5Images\\SampleMetalShots\\rot011.data");
            byte[] b022 = FileToByteArray("C:\\Users\\Gerhard J Norkus\\source\\repos\\SampleOpenCV\\Calibration5Images\\SampleMetalShots\\rot022.data");
            byte[] b033 = FileToByteArray("C:\\Users\\Gerhard J Norkus\\source\\repos\\SampleOpenCV\\Calibration5Images\\SampleMetalShots\\rot033.data");
            byte[] b045 = FileToByteArray("C:\\Users\\Gerhard J Norkus\\source\\repos\\SampleOpenCV\\Calibration5Images\\SampleMetalShots\\rot045.data");
            byte[] b056 = FileToByteArray("C:\\Users\\Gerhard J Norkus\\source\\repos\\SampleOpenCV\\Calibration5Images\\SampleMetalShots\\rot056.data");
            byte[] b067 = FileToByteArray("C:\\Users\\Gerhard J Norkus\\source\\repos\\SampleOpenCV\\Calibration5Images\\SampleMetalShots\\rot067.data");
            byte[] b078 = FileToByteArray("C:\\Users\\Gerhard J Norkus\\source\\repos\\SampleOpenCV\\Calibration5Images\\SampleMetalShots\\rot078.data");
            byte[] b090 = FileToByteArray("C:\\Users\\Gerhard J Norkus\\source\\repos\\SampleOpenCV\\Calibration5Images\\SampleMetalShots\\rot090.data");

            List<string[]> tstrs = new List<string[]>();
            List<string> tstrs2 = new List<string>();

            tstrs.Add(WriteToCsv(b000, "rot000", "C:\\Users\\Gerhard J Norkus\\source\\repos\\SampleOpenCV\\Calibration5Images\\SampleMetalShots\\rot000.txt", false, false));
            tstrs.Add(WriteToCsv(b011, "rot011", "C:\\Users\\Gerhard J Norkus\\source\\repos\\SampleOpenCV\\Calibration5Images\\SampleMetalShots\\rot011.txt", false, false));
            tstrs.Add(WriteToCsv(b022, "rot022", "C:\\Users\\Gerhard J Norkus\\source\\repos\\SampleOpenCV\\Calibration5Images\\SampleMetalShots\\rot022.txt", false, false));
            tstrs.Add(WriteToCsv(b033, "rot033", "C:\\Users\\Gerhard J Norkus\\source\\repos\\SampleOpenCV\\Calibration5Images\\SampleMetalShots\\rot033.txt", false, false));
            tstrs.Add(WriteToCsv(b045, "rot045", "C:\\Users\\Gerhard J Norkus\\source\\repos\\SampleOpenCV\\Calibration5Images\\SampleMetalShots\\rot045.txt", false, false));
            tstrs.Add(WriteToCsv(b056, "rot056", "C:\\Users\\Gerhard J Norkus\\source\\repos\\SampleOpenCV\\Calibration5Images\\SampleMetalShots\\rot056.txt", false, false));
            tstrs.Add(WriteToCsv(b067, "rot067", "C:\\Users\\Gerhard J Norkus\\source\\repos\\SampleOpenCV\\Calibration5Images\\SampleMetalShots\\rot067.txt", false, false));
            tstrs.Add(WriteToCsv(b078, "rot078", "C:\\Users\\Gerhard J Norkus\\source\\repos\\SampleOpenCV\\Calibration5Images\\SampleMetalShots\\rot078.txt", false, false));
            tstrs.Add(WriteToCsv(b090, "rot090", "C:\\Users\\Gerhard J Norkus\\source\\repos\\SampleOpenCV\\Calibration5Images\\SampleMetalShots\\rot090.txt", false, false));
            tstrs.Add(WriteToCsv(b078, "rot102", "C:\\Users\\Gerhard J Norkus\\source\\repos\\SampleOpenCV\\Calibration5Images\\SampleMetalShots\\rot102.txt", false, true));
            tstrs.Add(WriteToCsv(b067, "rot113", "C:\\Users\\Gerhard J Norkus\\source\\repos\\SampleOpenCV\\Calibration5Images\\SampleMetalShots\\rot113.txt", false, true));
            tstrs.Add(WriteToCsv(b056, "rot124", "C:\\Users\\Gerhard J Norkus\\source\\repos\\SampleOpenCV\\Calibration5Images\\SampleMetalShots\\rot124.txt", false, true));
            tstrs.Add(WriteToCsv(b045, "rot135", "C:\\Users\\Gerhard J Norkus\\source\\repos\\SampleOpenCV\\Calibration5Images\\SampleMetalShots\\rot135.txt", false, true));
            tstrs.Add(WriteToCsv(b033, "rot146", "C:\\Users\\Gerhard J Norkus\\source\\repos\\SampleOpenCV\\Calibration5Images\\SampleMetalShots\\rot146.txt", false, true));
            tstrs.Add(WriteToCsv(b022, "rot157", "C:\\Users\\Gerhard J Norkus\\source\\repos\\SampleOpenCV\\Calibration5Images\\SampleMetalShots\\rot157.txt", false, true));
            tstrs.Add(WriteToCsv(b011, "rot168", "C:\\Users\\Gerhard J Norkus\\source\\repos\\SampleOpenCV\\Calibration5Images\\SampleMetalShots\\rot168.txt", false, true));
            tstrs.Add(WriteToCsv(b000, "rot180", "C:\\Users\\Gerhard J Norkus\\source\\repos\\SampleOpenCV\\Calibration5Images\\SampleMetalShots\\rot180.txt", false, true));
            tstrs.Add(WriteToCsv(b011, "rot191", "C:\\Users\\Gerhard J Norkus\\source\\repos\\SampleOpenCV\\Calibration5Images\\SampleMetalShots\\rot191.txt", true, false));
            tstrs.Add(WriteToCsv(b022, "rot202", "C:\\Users\\Gerhard J Norkus\\source\\repos\\SampleOpenCV\\Calibration5Images\\SampleMetalShots\\rot202.txt", true, false));
            tstrs.Add(WriteToCsv(b033, "rot213", "C:\\Users\\Gerhard J Norkus\\source\\repos\\SampleOpenCV\\Calibration5Images\\SampleMetalShots\\rot213.txt", true, false));
            tstrs.Add(WriteToCsv(b045, "rot225", "C:\\Users\\Gerhard J Norkus\\source\\repos\\SampleOpenCV\\Calibration5Images\\SampleMetalShots\\rot225.txt", true, false));
            tstrs.Add(WriteToCsv(b056, "rot236", "C:\\Users\\Gerhard J Norkus\\source\\repos\\SampleOpenCV\\Calibration5Images\\SampleMetalShots\\rot236.txt", true, false));
            tstrs.Add(WriteToCsv(b067, "rot247", "C:\\Users\\Gerhard J Norkus\\source\\repos\\SampleOpenCV\\Calibration5Images\\SampleMetalShots\\rot247.txt", true, false));
            tstrs.Add(WriteToCsv(b078, "rot258", "C:\\Users\\Gerhard J Norkus\\source\\repos\\SampleOpenCV\\Calibration5Images\\SampleMetalShots\\rot258.txt", true, false));
            tstrs.Add(WriteToCsv(b090, "rot270", "C:\\Users\\Gerhard J Norkus\\source\\repos\\SampleOpenCV\\Calibration5Images\\SampleMetalShots\\rot270.txt", true, false));
            tstrs.Add(WriteToCsv(b078, "rot282", "C:\\Users\\Gerhard J Norkus\\source\\repos\\SampleOpenCV\\Calibration5Images\\SampleMetalShots\\rot282.txt", true, true));
            tstrs.Add(WriteToCsv(b067, "rot293", "C:\\Users\\Gerhard J Norkus\\source\\repos\\SampleOpenCV\\Calibration5Images\\SampleMetalShots\\rot293.txt", true, true));
            tstrs.Add(WriteToCsv(b056, "rot304", "C:\\Users\\Gerhard J Norkus\\source\\repos\\SampleOpenCV\\Calibration5Images\\SampleMetalShots\\rot304.txt", true, true));
            tstrs.Add(WriteToCsv(b045, "rot315", "C:\\Users\\Gerhard J Norkus\\source\\repos\\SampleOpenCV\\Calibration5Images\\SampleMetalShots\\rot315.txt", true, true));
            tstrs.Add(WriteToCsv(b033, "rot326", "C:\\Users\\Gerhard J Norkus\\source\\repos\\SampleOpenCV\\Calibration5Images\\SampleMetalShots\\rot326.txt", true, true));
            tstrs.Add(WriteToCsv(b022, "rot337", "C:\\Users\\Gerhard J Norkus\\source\\repos\\SampleOpenCV\\Calibration5Images\\SampleMetalShots\\rot337.txt", true, true));
            tstrs.Add(WriteToCsv(b011, "rot348", "C:\\Users\\Gerhard J Norkus\\source\\repos\\SampleOpenCV\\Calibration5Images\\SampleMetalShots\\rot348.txt", true, true));

            for (int i=0; i<tstrs.Count; i++)
            {
                for (int j=0; j<tstrs[i].Length; j++)
                {
                    tstrs2.Add(tstrs[i][j]);
                }
            }

            File.WriteAllLines("C:\\Users\\Gerhard J Norkus\\source\\repos\\SampleOpenCV\\Calibration5Images\\SampleMetalShots\\rot000.txt", tstrs2.ToArray());
            */
            lineConvMats.Add(rot000);
            lineConvMats.Add(rot011);
            lineConvMats.Add(rot022);
            lineConvMats.Add(rot033);
            lineConvMats.Add(rot045);
            lineConvMats.Add(rot056);
            lineConvMats.Add(rot067);
            lineConvMats.Add(rot078);
            lineConvMats.Add(rot090);
            lineConvMats.Add(rot102);
            lineConvMats.Add(rot113);
            lineConvMats.Add(rot124);
            lineConvMats.Add(rot135);
            lineConvMats.Add(rot146);
            lineConvMats.Add(rot157);
            lineConvMats.Add(rot168);
            lineConvMats.Add(rot180);
            lineConvMats.Add(rot191);
            lineConvMats.Add(rot202);
            lineConvMats.Add(rot213);
            lineConvMats.Add(rot225);
            lineConvMats.Add(rot236);
            lineConvMats.Add(rot247);
            lineConvMats.Add(rot258);
            lineConvMats.Add(rot270);
            lineConvMats.Add(rot282);
            lineConvMats.Add(rot293);
            lineConvMats.Add(rot304);
            lineConvMats.Add(rot315);
            lineConvMats.Add(rot326);
            lineConvMats.Add(rot337);
            lineConvMats.Add(rot348);
        }

        public string[] WriteToCsv(byte[] arr11x11, string szvarname, string szname, bool bFlipX=false, bool bFlipY=false)
        {
            int i, j, cnt;
            int a;
            float f;
            string[] tstr = new string[11];
            string[] tstr2 = new string[11];    

            cnt = 0;
            for (i=0; i<11; i++)
            {
                tstr[i] = "{";
                cnt = i * 11;
                if (bFlipX)
                    cnt += 10;

                for (j=0; j<11; j++)
                {
                    a = (int) arr11x11[cnt * 2];
                    a = a - 127;
                    f = (float)a / 127.0F;
                    if (bFlipX)
                        cnt--;
                    else
                        cnt++;
                    tstr[i] += f.ToString("##0.000000") + "F";
                    if (j!=10)
                        tstr[i] += ",";
                }
                tstr[i] += "},";
            }

            if (bFlipY == false)
            {
                for (i = 0; i < 11; i++)
                    tstr2[i] = tstr[i];
            }
            else
            {
                for (i = 0; i < 11; i++)
                    tstr2[10 - i] = tstr[i];
            }

            tstr2[0] = "float[,] " + szvarname + " = { \r\n" + tstr2[0];
            tstr2[10] += "};\r\n\r\n";

            return tstr2;

            //File.WriteAllLines(szname, tstr2);
        }
        public void WriteToCs(byte[] arr11x11, string szname)
        {
        }

        public byte[] FileToByteArray(string fileName)
        {
            byte[] buff = null;
            FileStream fs = new FileStream(fileName,
                                           FileMode.Open,
                                           FileAccess.Read);
            BinaryReader br = new BinaryReader(fs);
            long numBytes = new FileInfo(fileName).Length;
            buff = br.ReadBytes((int)numBytes);
            return buff;
        }

        private void OnExit(object sender, ExitEventArgs e)
        {
            //Properties.Settings.Default.Save();
        }

        [System.Runtime.InteropServices.DllImport("gdi32.dll")]
        public static extern bool DeleteObject(IntPtr hObject);


        public static BitmapSource ToBitmapSource(Emgu.CV.Mat image)
        {
            using (System.Drawing.Bitmap source = Emgu.CV.BitmapExtension.ToBitmap(image))
            {
                IntPtr ptr = source.GetHbitmap(); //obtain the Hbitmap

                BitmapSource bs = System.Windows.Interop.Imaging.CreateBitmapSourceFromHBitmap(
                    ptr,
                    IntPtr.Zero,
                    Int32Rect.Empty,
                    System.Windows.Media.Imaging.BitmapSizeOptions.FromEmptyOptions());

                DeleteObject(ptr); //release the HBitmap
                return bs;
            }
        }

        public static BitmapSource ToBitmapSource<TColor, TDepth>(Emgu.CV.Image<TColor, TDepth> image)
            where TColor : struct, Emgu.CV.IColor
            where TDepth : new()
        {
            using (System.Drawing.Bitmap source = image.AsBitmap())
            {
                IntPtr ptr = source.GetHbitmap(); //obtain the Hbitmap

                BitmapSource bs = System.Windows.Interop.Imaging.CreateBitmapSourceFromHBitmap(
                    ptr,
                    IntPtr.Zero,
                    Int32Rect.Empty,
                    System.Windows.Media.Imaging.BitmapSizeOptions.FromEmptyOptions());

                DeleteObject(ptr); //release the HBitmap
                return bs;
            }
        }


        // UndistortBigImage(cvimgGrayBefore, cameraMatrix, distortionMatrix);
        public Image<TColor, TDepth> UndistortBigImage<TColor, TDepth>(Image<TColor, TDepth> cvimgBefore)
            where TColor : struct, Emgu.CV.IColor
            where TDepth : new()
        {
            System.Drawing.Size orgImageSize = new System.Drawing.Size(cvimgBefore.Size.Width, cvimgBefore.Size.Height);

            System.Drawing.Size newImageSize = new System.Drawing.Size(cvimgBefore.Size.Width * 3 / 2, cvimgBefore.Size.Height * 3 / 2);
            Emgu.CV.Image<TColor, TDepth> cvimgBigColor = new Image<TColor, TDepth>(newImageSize.Width, newImageSize.Height);

            cvimgBigColor.ROI = new System.Drawing.Rectangle(0, 0, orgImageSize.Width, orgImageSize.Height);
            cvimgBefore.CopyTo(cvimgBigColor);
            cvimgBigColor.ROI = new System.Drawing.Rectangle(0, 0, newImageSize.Width, newImageSize.Height);

            System.Drawing.Rectangle validROI = new Rectangle();

            Emgu.CV.Mat newCameraMat = CvInvoke.GetOptimalNewCameraMatrix(cameraMatrix.Mat
                                                           , distortionMatrix.Mat
                                                           , orgImageSize
                                                           , 1
                                                           , newImageSize
                                                           , ref validROI);

            Emgu.CV.Image<TColor, TDepth> cvimgUndistorted = new Emgu.CV.Image<TColor, TDepth>(newImageSize.Width, newImageSize.Height);

            // Undistort the image using the stored camera parameters
            CvInvoke.Undistort(cvimgBigColor, cvimgUndistorted, cameraMatrix, distortionMatrix, newCameraMat);

            // Search the four sides for where the black stops
            int nLeft, nRight, nTop, nBottom, nTempY, nTempX;
            Object pixelZeroColor;

            if (typeof(TColor) == typeof(Bgr))
            {
                pixelZeroColor = new Bgr(0, 0, 0);
            }
            else
            if (typeof(TColor) == typeof(Bgra))
            {
                pixelZeroColor = new Bgra(0, 0, 0, 0);
            }
            else
            {
                pixelZeroColor = new Gray(0);
            }

            nTempY = cvimgUndistorted.Height / 2;
            nTempX = cvimgUndistorted.Width / 2;

            for (nLeft = 0; nLeft < cvimgUndistorted.Width; nLeft++)
            {
                if (cvimgUndistorted[nTempY, nLeft].Equals(pixelZeroColor) == false)
                    break;
            }

            for (nRight = cvimgUndistorted.Width - 1; nRight >= 0; nRight--)
            {
                if (cvimgUndistorted[nTempY, nRight].Equals(pixelZeroColor) == false)
                    break;
            }

            for (nTop = 0; nTop < cvimgUndistorted.Height; nTop++)
            {
                if (cvimgUndistorted[nTop, nTempX].Equals(pixelZeroColor) == false)
                    break;
            }

            for (nBottom = cvimgUndistorted.Height - 1; nBottom >= 0; nBottom--)
            {
                if (cvimgUndistorted[nBottom, nTempX].Equals(pixelZeroColor) == false)
                    break;
            }

            nTempY = 0;

            cvimgUndistorted.ROI = new Rectangle(nLeft, nTop, nRight - nLeft, nBottom - nTop);

            return cvimgUndistorted;
        }

        private void testCode1()
        {
            #region TestCode1

            OpenFileDialog openPic = new OpenFileDialog();

            if (openPic.ShowDialog() == true)
            {
                // Get the CV image from the file
                Emgu.CV.Image<Bgr, Byte> cvimgColor = new Image<Bgr, Byte>(openPic.FileName);



                // Convert the CV image to a GDI bitmap and store it in the
                // image control
                //gdiImage.Source = ToBitmapSource<Bgr, Byte>(cvimgColor);

                // Make sure we do matrix operations
                using UMat gray = new UMat();
                using Mat img = new Mat();
                cvimgColor.Mat.CopyTo(img);


                using UMat cannyEdges = new UMat();
                using Mat lineImage = new Mat(img.Size, DepthType.Cv8U, 3);
                using Mat triangleRectangleImage = new Mat(img.Size, DepthType.Cv8U, 3);


                // Convert the image to grayscale
                CvInvoke.CvtColor(img, gray, ColorConversion.Bgr2Gray);
                Image<Bgr, Byte> cvimgGraySrc = gray.ToImage<Bgr, Byte>();

                // Remove noise using gaussian blur
                System.Drawing.Size sz = new System.Drawing.Size(11, 11);
                CvInvoke.GaussianBlur(gray, gray, sz, 0);

                // Copy to the UMat to the gdiImage

                gdiImage.Source = ToBitmapSource<Bgr, Byte>(cvimgGraySrc);

                #region Canny and edge detection
                double cannyThreshold = 180.0;
                double cannyThresholdLinking = 120.0;
                CvInvoke.Canny(gray, cannyEdges, cannyThreshold, cannyThresholdLinking);
                LineSegment2D[] lines = CvInvoke.HoughLinesP(
                    cannyEdges,
                    1, //Distance resolution in pixel-related units
                    Math.PI / 45.0, //Angle resolution measured in radians.
                    20, //threshold
                    30, //min Line width
                    10); //gap between lines
                #endregion

                #region Find triangles and rectangles
                List<Triangle2DF> triangleList = new List<Triangle2DF>();
                List<RotatedRect> boxList = new List<RotatedRect>(); //a box is a rotated rectangle
                using (VectorOfVectorOfPoint contours = new VectorOfVectorOfPoint())
                {
                    CvInvoke.FindContours(cannyEdges, contours, null, RetrType.List,
                        ChainApproxMethod.ChainApproxSimple);
                    int count = contours.Size;
                    for (int i = 0; i < count; i++)
                    {
                        using (VectorOfPoint contour = contours[i])
                        using (VectorOfPoint approxContour = new VectorOfPoint())
                        {
                            CvInvoke.ApproxPolyDP(contour, approxContour, CvInvoke.ArcLength(contour, true) * 0.05,
                                true);
                            if (CvInvoke.ContourArea(approxContour, false) > 250
                            ) //only consider contours with area greater than 250
                            {
                                if (approxContour.Size == 3) //The contour has 3 vertices, it is a triangle
                                {
                                    System.Drawing.Point[] pts = approxContour.ToArray();
                                    triangleList.Add(new Triangle2DF(
                                        pts[0],
                                        pts[1],
                                        pts[2]
                                    ));
                                }
                                else if (approxContour.Size == 4) //The contour has 4 vertices.
                                {
                                    #region determine if all the angles in the contour are within [80, 100] degree
                                    bool isRectangle = true;
                                    System.Drawing.Point[] pts = approxContour.ToArray();
                                    LineSegment2D[] edges = PointCollection.PolyLine(pts, true);

                                    for (int j = 0; j < edges.Length; j++)
                                    {
                                        double angle = Math.Abs(
                                            edges[(j + 1) % edges.Length].GetExteriorAngleDegree(edges[j]));
                                        if (angle < 80 || angle > 100)
                                        {
                                            isRectangle = false;
                                            break;
                                        }
                                    }

                                    #endregion

                                    if (isRectangle) boxList.Add(CvInvoke.MinAreaRect(approxContour));
                                }
                            }
                        }
                    }
                }
                #endregion


                #region draw triangles and rectangles
                foreach (RotatedRect box in boxList)
                {
                    CvInvoke.Polylines(triangleRectangleImage, Array.ConvertAll(box.GetVertices(), System.Drawing.Point.Round), true,
                        new Bgr(Color.DarkOrange).MCvScalar, 2);
                }

                //Drawing a light gray frame around the image
                CvInvoke.Rectangle(triangleRectangleImage,
                    new Rectangle(System.Drawing.Point.Empty,
                        new System.Drawing.Size(triangleRectangleImage.Width - 1, triangleRectangleImage.Height - 1)),
                    new MCvScalar(120, 120, 120));
                //Draw the labels
                CvInvoke.PutText(triangleRectangleImage, "Triangles and Rectangles", new System.Drawing.Point(20, 20),
                    FontFace.HersheyDuplex, 0.5, new MCvScalar(120, 120, 120));
                #endregion

                //Image<Gray, Byte> cvimgGray2 = gray.ToImage<Gray, Byte>();
                Image<Bgr, Byte> cvimgGray2 = triangleRectangleImage.ToImage<Bgr, Byte>();



                // Convert the CV image from color to gray
                // Apply the Canny operator
                //Emgu.CV.Image<Gray, byte> grayImageCV = colorImageCV.Convert<Gray, byte>();
                //Emgu.CV.Image<Gray, byte> edgesCV = grayImageCV.Canny(50, 150);

                // To do a Hough transform, we need to use the Hue Sat Val colorspace
                // rather than RGB.  So, convert image to hsv
                //Image<Hsv, Byte> cvimgHsv2 = colorImageCV.Convert<Hsv, Byte>();
                //Image<Bgr, Byte> cvimgRGBResult = colorImageCV.Convert<Bgr, Byte>();

                //Image<Gray, Byte> cvimgGray = cvimgColor.Convert<Gray, Byte>();
                //Image<Gray, Byte> cvimgRGBResult = cvimgGray.Copy();

                // Get the lines from the Hough function
                //LineSegment2D[][] lines = cvimgHsv2.HoughLines  ( 50.0
                //                                              , 200.0
                //                                            , 1
                //                                          , Math.PI / 180.0
                //                                        , 50
                //                                      , 50.0
                //                                    , 10.10 );


                //cvimgRGBResult.SetZero();
                //for (int i = 0; i < lines[0].Length; i++)
                //{
                //  cvimgRGBResult.Draw(lines[0][i], new Bgr(255.0, 0.0, 0.0), 1);
                //}

                gdiGreyImage.Source = ToBitmapSource(cvimgGray2);

            }
            #endregion
        }

        private void DetectCorners()
        {
            #region DetectCorners
            OpenFileDialog openPic = new OpenFileDialog();

            // First, open the image captured that has the plates (or paper pieces)
            // and the ArUco corner targets.
            openPic.Multiselect = false;
            openPic.Title = "Open Aruco Image";

            if (cameraMatrix != null)
            {
                if (properties.SampleOpenCV.Default.CameraMatrix.Length > 0)
                {
                    XmlReader rdr = XmlReader.Create(new StringReader(properties.SampleOpenCV.Default.CameraMatrix));
                    if (rdr != null)
                    {
                        object o = (new XmlSerializer(typeof(Matrix<double>))).Deserialize(rdr);
                        if (o != null)
                            cameraMatrix = (Matrix<double>)o;
                    }
                }
            }
            if (distortionMatrix != null)
            {
                if (properties.SampleOpenCV.Default.DistortionMatrix.Length > 0)
                {
                    XmlReader rdr = XmlReader.Create(new StringReader(properties.SampleOpenCV.Default.DistortionMatrix));
                    if (rdr != null)
                    {
                        object o = (new XmlSerializer(typeof(Matrix<double>))).Deserialize(rdr);
                        if (o != null)
                            distortionMatrix = (Matrix<double>)o;
                    }
                }
            }

            if (openPic.ShowDialog() == true)
            {
                string szFileNameOnly = System.IO.Path.GetFileName(openPic.FileName);
                Title = "MainWindow - Calibration Image Loaded - " + szFileNameOnly;

                List<Emgu.CV.Image<Bgr, Byte>> cvimgsColor = new List<Image<Bgr, byte>>();

                // Open the target image
                cvimgsColor.Add(new Image<Bgr, Byte>(openPic.FileName));

                // Return Value allocation
                VectorOfVectorOfPointF myMarkerCorners = new VectorOfVectorOfPointF();
                VectorOfVectorOfPointF myRejects = new VectorOfVectorOfPointF();
                VectorOfInt myMarkerIds = new VectorOfInt();

                // Get the default parameters for the conversion
                //DetectorParameters myDetectorParams = new DetectorParameters();
                //myDetectorParams = DetectorParameters.GetDefault();
                DetectorParameters myDetectorParams = DetectorParameters.GetDefault();

                // Create the dictionary for receiving values
                Dictionary myDict = new Dictionary(Dictionary.PredefinedDictionaryName.DictArucoOriginal);

                // Some image result holders
                Emgu.CV.Image<Bgr, Byte> cvimgColorBefore = new Image<Bgr, Byte>(openPic.FileName);
                Emgu.CV.Image<Bgr, Byte> cvimgColor = new Image<Bgr, Byte>(openPic.FileName);
                Emgu.CV.Image<Gray, byte> cvimgGrayBefore = cvimgColor.Convert<Gray, byte>();
                Emgu.CV.Image<Gray, byte> cvimgGray = cvimgColor.Convert<Gray, byte>();

                // Using the camera calibration data from the checkerboard patterns, and the 
                // distortion array calculated from those images, undistort the images so it's
                // a TRUE camera projection with no induced curves.  We use our own undistort
                // so that we can get the maximum amount of pixels.
                cvimgGray = UndistortBigImage<Gray, Byte>(cvimgGrayBefore);
                cvimgColor = UndistortBigImage<Bgr, Byte>(cvimgColorBefore);

                // Store a gray result image
                gdiImage.Source = ToBitmapSource(cvimgGray);
                gdiGreyImage.Source = ToBitmapSource(cvimgColor);

                cvimgGrayBefore = cvimgColor.Convert<Gray, byte>();

                Emgu.CV.Mat imgInputAruco = cvimgGrayBefore.Mat;

                Emgu.CV.Aruco.ArucoInvoke.DetectMarkers(imgInputAruco, myDict, myMarkerCorners, myMarkerIds, myDetectorParams, myRejects);

                if (myMarkerCorners.Size == 4)
                {
                    // We're looking for the corners with the following IDs, in the following order:
                    ArucoInvoke.DrawDetectedMarkers(imgInputAruco, myMarkerCorners, myMarkerIds, new MCvScalar(255, 0, 255));
                    //Emgu.CV.Aruco.

                    // Draw the bounding corners...d
                    Dictionary<int, int> map = new Dictionary<int, int>();
                    map.Add(430, 0);
                    map.Add(219, 0);
                    map.Add(338, 1);
                    map.Add(908, 2);

                    Dictionary<int, PointF> mappts = new Dictionary<int, PointF>();
                    float dScaleFactor = 32.0F;

                    // The dimensions must not include the white border, which is 1/2"

                    float dLength = 133.25F;      // 134.25" - 1"
                    float dLength2 = 130F;        // 131" - 1"
                    float dWidth = 83.9375F;      //  84-15/16" - 1"


                    /*
                    float dLength = 134.25F;     
                    float dLength2 = 131F;       
                    float dWidth = 84.9375F;     
                    */

                    mappts.Add(430, new PointF(dLength2 * dScaleFactor, dWidth * dScaleFactor));
                    mappts.Add(219, new PointF(0.0F, dWidth * dScaleFactor));
                    mappts.Add(338, new PointF(0.0F, 0.0F));
                    mappts.Add(908, new PointF(dLength * dScaleFactor, 0.0F));

                    LineSegment2DF line;
                    line = new LineSegment2DF(myMarkerCorners[0][map[myMarkerIds[0]]], myMarkerCorners[1][map[myMarkerIds[1]]]);
                    cvimgColor.Draw(line, new Bgr(255.0, 0.0, 128.0), 1);
                    line = new LineSegment2DF(myMarkerCorners[1][map[myMarkerIds[1]]], myMarkerCorners[2][map[myMarkerIds[2]]]);
                    cvimgColor.Draw(line, new Bgr(255.0, 0.0, 128.0), 1);
                    line = new LineSegment2DF(myMarkerCorners[2][map[myMarkerIds[2]]], myMarkerCorners[3][map[myMarkerIds[3]]]);
                    cvimgColor.Draw(line, new Bgr(255.0, 0.0, 128.0), 1);
                    line = new LineSegment2DF(myMarkerCorners[3][map[myMarkerIds[3]]], myMarkerCorners[0][map[myMarkerIds[0]]]);
                    cvimgColor.Draw(line, new Bgr(255.0, 0.0, 128.0), 1);

                    PointF[] srcs = new PointF[4];
                    srcs[0] = myMarkerCorners[0][map[myMarkerIds[0]]];
                    srcs[1] = myMarkerCorners[1][map[myMarkerIds[1]]];
                    srcs[2] = myMarkerCorners[2][map[myMarkerIds[2]]];
                    srcs[3] = myMarkerCorners[3][map[myMarkerIds[3]]];

                    PointF[] dsts = new PointF[4];
                    dsts[0] = mappts[myMarkerIds[0]];
                    dsts[1] = mappts[myMarkerIds[1]];
                    dsts[2] = mappts[myMarkerIds[2]];
                    dsts[3] = mappts[myMarkerIds[3]];

                    Emgu.CV.Mat homog = CvInvoke.FindHomography(srcs, dsts);
                    homographyMatrix = new Matrix<double>(homog.Rows, homog.Cols);
                    homog.CopyTo(homographyMatrix);
                    invHomographyMatrix = new Matrix<double>(3, 3);
                    CvInvoke.Invert(homographyMatrix, invHomographyMatrix, DecompMethod.LU);

                    if (homographyMatrix != null)
                    {
                        // Store the intrinsics in the user settings
                        StringBuilder sb = new StringBuilder();
                        (new XmlSerializer(typeof(Matrix<double>))).Serialize(new StringWriter(sb), homographyMatrix);
                        properties.SampleOpenCV.Default.HomographyMatrix = sb.ToString();
                    }

                    properties.SampleOpenCV.Default.ResultScale = dScaleFactor;
                    properties.SampleOpenCV.Default.ResultLength = dLength;
                    properties.SampleOpenCV.Default.ResultWidth = dWidth;
                    properties.SampleOpenCV.Default.BorderBottom = 9.6875;
                    properties.SampleOpenCV.Default.BorderTop = 10.75;
                    properties.SampleOpenCV.Default.BorderLeft = 6.75;
                    properties.SampleOpenCV.Default.BorderRight = 2.5;
                    properties.SampleOpenCV.Default.Save();

                    Emgu.CV.Image<Gray, Byte> cvimgDewarped = cvimgGray.WarpPerspective<double>(homographyMatrix, (int)(dLength * dScaleFactor), (int)(dWidth * dScaleFactor), Inter.Cubic, Warp.Default, BorderType.Default, new Gray(0));

                    gdiGreyImage.Source = ToBitmapSource(cvimgDewarped);
                }
                else
                if (myMarkerCorners.Size > 4)
                {
                    // We're looking for the corners with the following IDs, in the following order:
                    ArucoInvoke.DrawDetectedMarkers(imgInputAruco, myMarkerCorners, myMarkerIds, new MCvScalar(255, 0, 255));
                    gdiGreyImage.Source = ToBitmapSource(imgInputAruco);
                }
                #endregion
            }
        }

        private List<MCvPoint3D32f> CreateObjectPoints(System.Drawing.Size sz, float w = 1.0f, float h = 1.0f)
        {
            float x, y;

            var chessboard = new List<MCvPoint3D32f>();

            for (y = 0; y < sz.Height; y++)
            {
                for (x = 0; x < sz.Width; x++)
                {
                    chessboard.Add(new MCvPoint3D32f(x * w, y * h, 0));
                }
            }

            return chessboard;
        }

        private void LoadCalibrationImages()
        {
            int i;
            List<Emgu.CV.Image<Bgr, Byte>> cvimgsColor = new List<Image<Bgr, byte>>();
            System.Drawing.Size patternSize = new System.Drawing.Size(9, 7);
            Mat[] rotationVectors;
            Mat[] translationVectors;
            Boolean bShow = false;

            MCvPoint3D32f[][] _cornersObjectList;
            PointF[][] _cornersPointsList;
            VectorOfPointF[] _cornersPointsVec;
            bool bFound;
            double error = 0.0;
            float sqW = 1.0f;
            float sqH = 0.997f;

            OpenFileDialog openPic = new OpenFileDialog();

            openPic.Multiselect = true;
            openPic.Title = "Open Calibration Images - Select Multiple Frames";

            if (openPic.ShowDialog() == true)
            {


                // Open all of the calibration images
                i = 0;
                foreach (String filename in openPic.FileNames)
                {
                    cvimgsColor.Add(new Image<Bgr, Byte>(filename));
                    i++;
                }

                #region Initialize Variable Arrays
                _cornersPointsVec = new VectorOfPointF[cvimgsColor.Count];
                _cornersObjectList = new MCvPoint3D32f[cvimgsColor.Count][];
                _cornersPointsList = new PointF[cvimgsColor.Count][];
                #endregion

                for (i = 0; i < cvimgsColor.Count; i++)
                {
                    Debug.WriteLine("Processing Image " + i.ToString() + " of " + cvimgsColor.Count);

                    #region First, convert the bitmap to gray
                    Emgu.CV.Image<Gray, byte> cvimgGray = cvimgsColor[i].Convert<Gray, byte>();
                    //Emgu.CV.Image<Gray, byte> cvimgAdaptThresh = cvimgGray.ThresholdAdaptive( new Gray(255)
                    //                                                                      , Emgu.CV.CvEnum.AdaptiveThresholdType.GaussianC
                    //                                                                    , Emgu.CV.CvEnum.ThresholdType.Binary
                    //                                                                  , 31
                    //                                                                , new Gray(-20));
                    //gdiGreyImage.Source = ToBitmapSource<Gray, Byte>(cvimgAdaptThresh);
                    Emgu.CV.Image<Gray, byte> cvimgAdaptThresh = cvimgGray.ThresholdBinary(new Gray(220), new Gray(255));
                    Emgu.CV.Image<Gray, byte> cvimgErode = cvimgAdaptThresh.Erode(1);
                    gdiGreyImage.Source = ToBitmapSource<Gray, Byte>(cvimgErode);
                    #endregion


                    #region Next, Find the chess board corners
                    _cornersPointsVec[i] = new VectorOfPointF();
                    bFound = CvInvoke.FindChessboardCorners(cvimgGray, patternSize, _cornersPointsVec[i]);
                    if (bFound)
                    {

                    }
                    else
                    {
                        MessageBox.Show("Couldn't find corners for " + openPic.FileNames[i]);
                    }
                    #endregion

                    #region Draw and display the corners on a color copy of the image
                    if (bFound)
                    {
                        CvInvoke.CornerSubPix(cvimgGray, _cornersPointsVec[i], new System.Drawing.Size(11, 11), new System.Drawing.Size(-1, -1), new MCvTermCriteria(30, 0.1));

                        Emgu.CV.Image<Bgr, Byte> cvimgColorCopy = cvimgsColor[i].Copy();

                        _cornersObjectList[i] = CreateObjectPoints(patternSize, sqW, sqH).ToArray();
                        _cornersPointsList[i] = _cornersPointsVec[i].ToArray();

                        // IMPORTANT NOTE!!!  DrawChessboardCorners requires that the cornersPointsVec
                        // be a PointF (float), not an int or a double.
                        CvInvoke.DrawChessboardCorners(cvimgColorCopy, patternSize, _cornersPointsVec[i], bFound);
                        gdiGreyImage.Source = ToBitmapSource<Bgr, Byte>(cvimgColorCopy);
                    }
                    else
                    {
                    }
                    #endregion

                    gdiImage.Source = ToBitmapSource<Bgr, Byte>(cvimgsColor[i]);

                    if (bShow)
                    {
                        if (MessageBox.Show("Image " + i.ToString() + "  Press OK to continue.") != MessageBoxResult.OK)
                            bShow = false;
                    }
                }


                #region Calibrate the camera and store the intrinsics                    


                error = CvInvoke.CalibrateCamera(_cornersObjectList
                                         , _cornersPointsList
                                         , cvimgsColor[0].Size
                                         , cameraMatrix
                                         , distortionMatrix
                                         , CalibType.Default
                                         , new MCvTermCriteria(250, 0.001)
                                         , out rotationVectors
                                         , out translationVectors);




                #endregion


                Rectangle rc = new Rectangle();
                Mat rval;

                rval = CvInvoke.GetOptimalNewCameraMatrix(cameraMatrix, distortionMatrix, cvimgsColor[0].Size, 1, cvimgsColor[0].Size, ref rc);
                bool bShowMsg = true;

                if (cameraMatrix != null)
                {
                    // Store the intrinsics in the user settings
                    StringBuilder sb = new StringBuilder();
                    (new XmlSerializer(typeof(Matrix<double>))).Serialize(new StringWriter(sb), cameraMatrix);
                    properties.SampleOpenCV.Default.CameraMatrix = sb.ToString();
                }

                if (distortionMatrix != null)
                {
                    // Store the intrinsics in the user settings
                    StringBuilder sb = new StringBuilder();
                    (new XmlSerializer(typeof(Matrix<double>))).Serialize(new StringWriter(sb), distortionMatrix);
                    properties.SampleOpenCV.Default.DistortionMatrix = sb.ToString();
                }

                Debug.WriteLine("Camera Matrix");
                Debug.WriteLine(properties.SampleOpenCV.Default.CameraMatrix);

                Debug.WriteLine("Distortion Matrix");
                Debug.WriteLine(properties.SampleOpenCV.Default.DistortionMatrix);

                properties.SampleOpenCV.Default.Save();



                for (i = 0; i < cvimgsColor.Count; i++)
                {
                    Emgu.CV.Image<Bgr, Byte> cvimgColorCopy = cvimgsColor[i].Copy();
                    Emgu.CV.Image<Bgr, Byte> cvimgColorResult = cvimgsColor[i].Copy();

                    CvInvoke.Undistort(cvimgColorCopy, cvimgColorResult, cameraMatrix, distortionMatrix);

                    gdiImage.Source = ToBitmapSource<Bgr, Byte>(cvimgColorResult);

                    CvInvoke.DrawChessboardCorners(cvimgColorCopy, patternSize, _cornersPointsVec[i], true);
                    gdiGreyImage.Source = ToBitmapSource<Bgr, Byte>(cvimgColorCopy);
                    if (bShowMsg)
                    {
                        MessageBoxResult res;

                        if (bShowMsg)
                        {
                            res = MessageBox.Show("Displaying Undistorted Image "
                                                    + i.ToString()
                                                    + "  Press OK to continue, or Cancel (Esc) to stop showing this message."
                                                , "Progress"
                                                , MessageBoxButton.OKCancel
                                                , MessageBoxImage.Warning
                                                 );

                            if (res == MessageBoxResult.Cancel)
                                bShowMsg = false;
                        }
                    }
                }
            }
        }



        private void SaveCornerDetectImage()
        {
            #region SaveCorners
            SaveFileDialog savePic = new SaveFileDialog();

            savePic.Title = "Save Detected Corner Image";
            savePic.Filter = "Png File|*.png";

            if (savePic.ShowDialog() == true)
            {
                var ext = Path.GetExtension(savePic.FileName);
                var name = Path.GetFileNameWithoutExtension(savePic.FileName);
                var dir = Path.GetDirectoryName(savePic.FileName);

                System.Windows.Media.ImageSource src = gdiImage.Source;
                BitmapSource bmpSource = src as BitmapSource;
                System.Windows.Media.Imaging.PngBitmapEncoder pngBitmapEncoder = new System.Windows.Media.Imaging.PngBitmapEncoder();
                System.IO.FileStream stream = new System.IO.FileStream(dir + "\\" + name + ext, FileMode.Create);
                pngBitmapEncoder.Interlace = PngInterlaceOption.On;
                pngBitmapEncoder.Frames.Add(System.Windows.Media.Imaging.BitmapFrame.Create(bmpSource));
                pngBitmapEncoder.Save(stream);
                stream.Flush();
                stream.Close();

                src = gdiGreyImage.Source;
                bmpSource = src as BitmapSource;
                pngBitmapEncoder = new System.Windows.Media.Imaging.PngBitmapEncoder();
                stream = new System.IO.FileStream(dir + "\\" + name + "2" + ext, FileMode.Create);
                pngBitmapEncoder.Interlace = PngInterlaceOption.On;
                pngBitmapEncoder.Frames.Add(System.Windows.Media.Imaging.BitmapFrame.Create(bmpSource));
                pngBitmapEncoder.Save(stream);
                stream.Flush();
                stream.Close();

            }

            #endregion
        }


        // helper function:
        // finds a cosine of angle between vectors
        // from pt0->pt1 and from pt0->pt2
        static double angle(System.Drawing.Point pt1, System.Drawing.Point pt2, System.Drawing.Point pt0)
        {
            double dx1 = pt1.X - pt0.X;
            double dy1 = pt1.Y - pt0.Y;
            double dx2 = pt2.X - pt0.X;
            double dy2 = pt2.Y - pt0.Y;
            return (dx1 * dx2 + dy1 * dy2) / Math.Sqrt((dx1 * dx1 + dy1 * dy1) * (dx2 * dx2 + dy2 * dy2) + 1e-10);
        }

        int thresh = 50;
        int N = 11;

        private void DetectShapes(Emgu.CV.Image<Bgr, Byte> myImage)
        {

        }

        // This uses the existing homography matrix to reverse the translation of line segments back
        // into the view.  This will later be used for 3D transformation if we have correct pose estimates.
        //private LineSegment2D[] TransformHomographyLines(LineSegment2D[] inputLines, bool bReverse )
        //{
        //Mat tMat = homographyMatrix.Mat();

        //CvInvoke.Invert(homographyMatrix, tMat, DecompMethod.Normal);
        //LineSegment2D[] outputLines = new LineSegment2D[inputLines.Length]; 
        //}

        private void CheckMatricesLoaded()
        {
            if (homographyMatrix != null)
            {
                XmlReader rdr = XmlReader.Create(new StringReader(properties.SampleOpenCV.Default.HomographyMatrix));
                if (rdr != null)
                {
                    object o = (new XmlSerializer(typeof(Matrix<double>))).Deserialize(rdr);
                    if (o != null)
                    {
                        homographyMatrix = (Matrix<double>)o;

                        invHomographyMatrix = new Matrix<double>(3, 3);
                        CvInvoke.Invert(homographyMatrix, invHomographyMatrix, DecompMethod.LU);
                    }
                }
            }
            if (cameraMatrix != null)
            {
                XmlReader rdr = XmlReader.Create(new StringReader(properties.SampleOpenCV.Default.CameraMatrix));
                if (rdr != null)
                {
                    object o = (new XmlSerializer(typeof(Matrix<double>))).Deserialize(rdr);
                    if (o != null)
                        cameraMatrix = (Matrix<double>)o;
                }
            }
            if (distortionMatrix != null)
            {
                XmlReader rdr = XmlReader.Create(new StringReader(properties.SampleOpenCV.Default.DistortionMatrix));
                if (rdr != null)
                {
                    object o = (new XmlSerializer(typeof(Matrix<double>))).Deserialize(rdr);
                    if (o != null)
                        distortionMatrix = (Matrix<double>)o;
                }
            }

        }

        private Image<Bgr,Byte> KMeansAttempt(Image<Bgr, Byte> byteSrc, int clusterCount, int attempts)
        {
            Image<Bgr, float> src = byteSrc.Convert<Bgr, float>();
            Matrix<float> samples = new Matrix<float>(src.Rows * src.Cols, 1, 3);
            Matrix<int> finalClusters = new Matrix<int>(src.Rows * src.Cols, 1);

            for (int y = 0; y<src.Rows; y++)
            {
                for (int x = 0; x<src.Cols; x++)
                {
                    samples.Data[y + x * src.Rows, 0] = (float) src[y, x].Blue;
                    samples.Data[y + x * src.Rows, 1] = (float) src[y, x].Green;
                    samples.Data[y + x * src.Rows, 2] = (float) src[y, x].Red;
                }
            }

            MCvTermCriteria term = new MCvTermCriteria(10000, 0.0001);
            term.Type = TermCritType.Iter | TermCritType.Eps;

            Matrix<Single> centers = new Matrix<Single>(clusterCount, samples.Cols, 3);
            //CvInvoke.cvKMeans2(samples, clusterCount, finalClusters, term, attempts, IntPtr.Zero, KMeansInitType.PPCenters, centers, IntPtr.Zero);
            CvInvoke.Kmeans(samples, clusterCount, finalClusters, term, attempts, KMeansInitType.PPCenters, centers);

            Image<Bgr, Byte> new_image = new Image<Bgr, Byte>(src.Size);

            for (int y = 0; y < src.Rows; y++)
            {
                for (int x = 0; x < src.Cols; x++)
                {
                    int cluster_idx = finalClusters[y + x * src.Rows, 0];
                    MCvScalar sca1 = CvInvoke.cvGet2D(centers, cluster_idx, 0);
                    Bgr color = new Bgr(sca1.V0, sca1.V1, sca1.V2);

                    PointF p = new PointF(x, y);
                    new_image.Draw(new CircleF(p, 1.0f), color, 1);
                }
            }
            return new_image;
        }

        PointF[] GetDefaultBorders()
        {
            // The default borders are in the order of TopLeft, TopRight, BottomRight, BottomLeft
            // This is so a single polyline command can be used to draw the border

            float dBorderTop = (float)properties.SampleOpenCV.Default.BorderTop;
            float dBorderBottom = (float)properties.SampleOpenCV.Default.BorderBottom;
            float dBorderRight = (float)properties.SampleOpenCV.Default.BorderRight;
            float dBorderLeft = (float)properties.SampleOpenCV.Default.BorderLeft;
            float dScaleFactor = (float)properties.SampleOpenCV.Default.ResultScale;
            float dLength = (float)properties.SampleOpenCV.Default.ResultLength;
            float dWidth = (float)properties.SampleOpenCV.Default.ResultWidth;

            //TopLeft
            PointF[] defaultBorders = new PointF[] { new PointF { X = dBorderLeft * dScaleFactor, Y = dBorderTop * dScaleFactor }
                                                   , new PointF { X = (dLength-dBorderRight) * dScaleFactor, Y = dBorderTop * dScaleFactor }
                                                   , new PointF { X = (dLength-dBorderRight) * dScaleFactor, Y = (dWidth-dBorderBottom) * dScaleFactor }
                                                   , new PointF { X = dBorderLeft * dScaleFactor, Y = (dWidth-dBorderBottom) * dScaleFactor } };

            return defaultBorders;
        }


        VectorOfVectorOfPointF vecRackPolys = new VectorOfVectorOfPointF();
        VectorOfVectorOfPoint vecMaskPolys = new VectorOfVectorOfPoint();
        Mat matFillPoints ;

        void GenerateDetectMaskPolys(System.Drawing.Size sz)
        {
            PointF[] dstBorders = GetDefaultBorders();   // TopL, TopR, BotR, BotL
            float dScaleFactor = (float)properties.SampleOpenCV.Default.ResultScale;
            float x, y, x2, y2;
            float xinc, yinc;
            ushort nPolyCnt;
            VectorOfPoint tpoly = new VectorOfPoint(4);
            VectorOfPointF srcPoly = new VectorOfPointF(4);
            Point[] destPoly = new Point[4];
            PointF[] spoly = new PointF[4];

            vecRackPolys.Clear();
            vecMaskPolys.Clear();

            xinc = 3.0F;  // increment of 2.5"
            yinc = 1.5F;  // increment of 2.5"

            nPolyCnt = 1;

            // Figure out how many neighbors connected points
            // have.  We use the flood fill method to join points.  
            // Of course, this is not optimized for video purposes.
            int tw = (int)Math.Floor(dstBorders[1].X - dstBorders[0].X);
            int txinc = (int)Math.Floor(dScaleFactor * xinc);
            int w = tw / txinc + (((tw % txinc)>0) ? 1 : 0);

            int th = (int)Math.Floor(dstBorders[3].Y - dstBorders[0].Y);
            int tyinc = (int)Math.Floor(dScaleFactor * yinc);
            int h = th / tyinc + (((th % tyinc) > 0) ? 1 : 0);

            matFillPoints = new Mat(h,w,DepthType.Cv32F,1);

            // Loop around to get the polygon borders.
            for (y = dstBorders[0].Y; y < dstBorders[3].Y; y += dScaleFactor * yinc)
            {
                for (x = dstBorders[0].X; x < dstBorders[1].X; x += dScaleFactor * xinc)
                {
                    x2 = x + dScaleFactor * xinc;
                    if (x2 > dstBorders[1].X)
                        x2 = dstBorders[1].X;

                    y2 = y + dScaleFactor * yinc;
                    if (y2 > dstBorders[3].Y)
                        y2 = dstBorders[3].Y;

                    spoly[0].X = x; spoly[1].X = x2-1; spoly[2].X = x2-1; spoly[3].X = x;
                    spoly[0].Y = y; spoly[1].Y = y;    spoly[2].Y = y2-1; spoly[3].Y = y2-1;

                    vecRackPolys.Push(new VectorOfPointF(spoly));

                    // Transform and convert to ints
                    PointF[] dpoly = CvInvoke.PerspectiveTransform(spoly, invHomographyMatrix);
                    for (int i = 0; i < 4; i++)
                        destPoly[i] = Point.Round(dpoly[i]);

                    vecMaskPolys.Push(new VectorOfPoint(destPoly));
                }
            }
        }

        // This method draws a series of parallelograms that represent hit test regions on the 
        // metal rack.  Usually, the metal rack or some noise will cause a hit in one of the
        // parallelograms.  If a parallelogram is hit, the subsequent filling mask will not
        // have the hit drawn.  This will leave us with just a few large areas that will likely
        // be close to the correct measure of the piece of metal being measured.  Some tolerance
        // of rotation can be expected, but not extreme angles.  Pieces of metal below a 
        // certain size threshold will be ignored.
        Emgu.CV.Image<Gray,ushort> DrawRectDetectMask<TColor, TDepth>(ref Emgu.CV.Image<TColor, TDepth> img)
            where TColor : struct, Emgu.CV.IColor
            where TDepth : new()
        {
            Emgu.CV.Image<Gray, ushort> rval = new Image<Gray, ushort>(img.Size);

            PointF[] dstBorders = GetDefaultBorders();   // TopL, TopR, BotR, BotL
            float dScaleFactor = (float)properties.SampleOpenCV.Default.ResultScale;
            float x, y, x2, y2;
            float xinc, yinc;
            ushort nPolyCnt;
            System.Drawing.Point[] tpoly = new Point[4];
            System.Drawing.PointF[] srcPoly = new PointF[4];

            xinc = 3.0F;  // increment of 2.5"
            yinc = 1.5F;  // increment of 2.5"

            nPolyCnt = 1;

            for (int i = 0; i < vecMaskPolys.Size; i++)
                rval.FillConvexPoly(vecMaskPolys[i].ToArray(), new Gray(nPolyCnt++));

            return rval;
        }

        private void EraseDrawingBorders<TColor,TDepth>(ref Emgu.CV.Image<TColor,TDepth> img)
            where TColor : struct, Emgu.CV.IColor
            where TDepth : new()
        {
            PointF[] dstBorders = GetDefaultBorders();
            PointF[] srcBorders = CvInvoke.PerspectiveTransform(dstBorders, invHomographyMatrix);

            // Use the points just calculated to make polygons...
            System.Drawing.Point[][] pts = new System.Drawing.Point[][]
            {
                    new Point[]
                    {
                          new Point{ X=0, Y=0 }
                        , Point.Round(srcBorders[0])
                        , Point.Round(srcBorders[1])
                        , new Point { X=img.Width, Y=0 }
                    },
                    new Point[]
                    {
                          new Point { X=img.Width, Y=0 }
                        , Point.Round(srcBorders[1])
                        , Point.Round(srcBorders[2])
                        , new Point { X=img.Width, Y=img.Height }
                    },
                    new Point[]
                    {
                          new Point { X=img.Width, Y=img.Height }
                        , Point.Round(srcBorders[2])
                        , Point.Round(srcBorders[3])
                        , new Point { X=0, Y=img.Height }
                    },
                    new Point[]
                    {
                          new Point { X=0, Y=img.Height }
                        , Point.Round(srcBorders[3])
                        , Point.Round(srcBorders[0])
                        , new Point{ X=0, Y=0 }
                    }
            };

            Object pixelBlackColor;
            if (typeof(TColor) == typeof(Bgr))
            {
                pixelBlackColor = new Bgr(0, 0, 0);
            }
            else
            if (typeof(TColor) == typeof(Bgra))
            {
                pixelBlackColor = new Bgra(0, 0, 0, 0);
            }
            else
            {
                pixelBlackColor = new Gray(0);
            }

            img.FillConvexPoly(pts[0], (TColor)pixelBlackColor);
            img.FillConvexPoly(pts[1], (TColor)pixelBlackColor);
            img.FillConvexPoly(pts[2], (TColor)pixelBlackColor);
            img.FillConvexPoly(pts[3], (TColor)pixelBlackColor);
        }

        private void DisplayEmptyPolys<TColor, TDepth>(ref Emgu.CV.Image<TColor,TDepth>img, ref float[] histIgnoreVals, bool bUseRealRack=false)
            where TColor : struct, Emgu.CV.IColor
            where TDepth : new()
        {
            int nFillVal = vecMaskPolys.Size;
            Object pixelWhiteColor;

            if (bUseRealRack)
            {
                for (int i = 0; i < vecRackPolys.Size; i++)
                {
                    if (histIgnoreVals[i + 1] == 0)
                    {
                        VectorOfPointF vpf = vecRackPolys[i];
                        VectorOfPoint vp = new VectorOfPoint();

                        PointF[] pfa = vecRackPolys[i].ToArray();
                        Point[] pa = new Point[pfa.Length];

                        for (int j = 0; j < vpf.Size; j++)
                            pa[j] = Point.Round(pfa[j]);

                        if (typeof(TColor) == typeof(Bgr))
                        {
                            pixelWhiteColor = new Bgr(255, 255, 255);
                        }
                        else
                        if (typeof(TColor) == typeof(Bgra))
                        {
                            pixelWhiteColor = new Bgra(255, 255, 255, 255);
                        }
                        else
                        {
                            if (typeof(TDepth) == typeof(byte))
                                pixelWhiteColor = new Gray(255);
                            else
                                pixelWhiteColor = new Gray(nFillVal);
                        }
                        img.FillConvexPoly(pa, (TColor)pixelWhiteColor);
                    }
                }

            }
            else
            {
                for (int i = 0; i < vecMaskPolys.Size; i++)
                {
                    if (histIgnoreVals[i + 1] == 0)
                    {
                        if (typeof(TColor) == typeof(Bgr))
                        {
                            pixelWhiteColor = new Bgr(255, 255, 255);
                        }
                        else
                        if (typeof(TColor) == typeof(Bgra))
                        {
                            pixelWhiteColor = new Bgra(255, 255, 255, 255);
                        }
                        else
                        {
                            if (typeof(TDepth) == typeof(byte))
                                pixelWhiteColor = new Gray(255);
                            else
                                pixelWhiteColor = new Gray(nFillVal);
                        }
                        img.FillConvexPoly(vecMaskPolys[i].ToArray(), (TColor)pixelWhiteColor);
                    }
                }
            }
        }

        private void CalcEmptyPolys( ref Emgu.CV.Image<Gray, ushort> imgSrc
                                   , ref Emgu.CV.Image<Gray, ushort> imgResult
                                   , ref float[] histIgnoreValsResult)
        {
            int x, y;
            int i;
            Mat mask;
            Rectangle rc = new Rectangle();
            int n;
            string tstr;
            int ix, iy;
            List<System.Drawing.Point> vop = new List<System.Drawing.Point>();
            List<int> voi = new List<int>();
            List<System.Drawing.Point> vopr = new List<System.Drawing.Point>();
            List<int> voir = new List<int>();
            System.Drawing.Point pt = new Point();

            Emgu.CV.Image<Gray, ushort> timg = DrawRectDetectMask<Gray, ushort>(ref imgSrc);
            imgResult = imgSrc.And(imgResult);

            DenseHistogram Histo = new DenseHistogram(65536, new RangeF(0, 65536));
            Histo.Calculate<ushort>(new Image<Gray, ushort>[] { imgResult }, true, null);
            histIgnoreValsResult = Histo.GetBinValues();

            // Initialize the fill values to a single value
            matFillPoints.SetTo(new Gray(0F).MCvScalar);
            mask = new Mat(matFillPoints.Size + new System.Drawing.Size(2,2), DepthType.Cv8U, 1);

            // Now that we have the bin values, we can populate the testemptymatrix
            // We take advantage of the fact that the fill values are the same size (+1)
            // as the matFillPoints
            i = 1;
            for (y=0; y<matFillPoints.Rows; y++)
            {
                for (x=0; x<matFillPoints.Cols; x++)
                {
                    matFillPoints.SetValue(y, x, (histIgnoreValsResult[i] == 0) ? 32767F : 0F);
                    i++;
                }    
            }

            // Now, loop through the values and do a floodfill whenever we see a 65535

            i = 1;
            for (pt.Y = 0; pt.Y < matFillPoints.Rows; pt.Y++)
            {
                for (pt.X = 0; pt.X< matFillPoints.Cols; pt.X++)
                {
                    if (matFillPoints.GetValue(pt.Y, pt.X) == 32767F)
                    {
                        voi.Add(CvInvoke.FloodFill(matFillPoints, null, pt, new Gray(i).MCvScalar, out rc
                            , new Gray(0F).MCvScalar, new Gray(0F).MCvScalar, Connectivity.EightConnected, FloodFillType.FixedRange));
                        vop.Add(pt);
                        i++;
                    }
                }
            }

            for (i=0; i<voi.Count; i++)
            {
                if (voi[i] <= 2)
                {
                    voir.Add(CvInvoke.FloodFill(matFillPoints, null, vop[i], new Gray(0).MCvScalar, out rc
                                     , new Gray(0F).MCvScalar, new Gray(0F).MCvScalar, Connectivity.EightConnected, FloodFillType.FixedRange));
                    vopr.Add(vop[i]);
                }
            }

            i = 1;
            for (iy = 0; iy < matFillPoints.Rows; iy++)
            {
                for (ix = 0; ix < matFillPoints.Cols; ix++)
                {
                    n = (int)matFillPoints.GetValue(iy, ix);
                    i++;
                    if ( (n == 0) && (histIgnoreValsResult[i] == 0) )
                        histIgnoreValsResult[i] = 1;
                }
            }
        }

        string szLastFileName = "";

        private void DetectEdges(bool bDoFileOpen)
        {
            double dLength = properties.SampleOpenCV.Default.ResultLength;
            double dWidth = properties.SampleOpenCV.Default.ResultWidth;
            double dScaleFactor = properties.SampleOpenCV.Default.ResultScale;
            float dScaleFactorF = (float)dScaleFactor;
            string szOrgImage ;
            float dMedianWidthF;
            float dMedianHeightF;

            if (dLength * dWidth * dScaleFactor <= 0)
            {
                MessageBox.Show("Please press the Load ARuCo Images button and select a calibration image before attempting this action.");
                return;
            }

            CheckMatricesLoaded();

            if (bDoFileOpen)
            {
                OpenFileDialog openPic = new OpenFileDialog();
                openPic.Multiselect = false;
                openPic.Title = "Open Background Image";
                if (openPic.ShowDialog() == false)
                {
                    return;
                }

                szOrgImage = openPic.FileName;
                szLastFileName = szOrgImage;

                Title = "MainWindow - Undistort File - " + System.IO.Path.GetFileName(szLastFileName); ;

            }
            else
            {
                szOrgImage = szLastFileName;
                if (szOrgImage.Length == 0)
                {
                    MessageBox.Show("Please select a file using UndistortImage before trying to Redo");
                    return;
                }
                Title = "MainWindow - Undistort Recalculating - " + System.IO.Path.GetFileName(szLastFileName); ;
            }

            Emgu.CV.Image<Bgr, Byte> cvimgColor = new Image<Bgr, Byte>(szOrgImage);
            Emgu.CV.Image<Bgra, Byte> cvimgColorBgra = new Image<Bgra, Byte>(szOrgImage);
            Emgu.CV.Image<Bgra, Byte> cvimgOutput = new Image<Bgra, Byte>(cvimgColorBgra.Width, cvimgColorBgra.Height);

            CudaImage<Bgra, byte> cudaImage = new CudaImage<Bgra, byte>(cvimgColorBgra);
            CudaImage<Bgra, byte> cudaImageOut = new CudaImage<Bgra, byte>(cvimgColorBgra);

            int nNumIterations = int.Parse(NumIterations.Text);
            int nSegmentLength = int.Parse(SegmentLength.Text);
            int nColorRadius = int.Parse(ColorRadius.Text);
            int nSpatialRadius = int.Parse(SpatialRadius.Text);

            CudaInvoke.MeanShiftSegmentation(cudaImage, cvimgOutput, nSpatialRadius, nColorRadius, nSegmentLength, new MCvTermCriteria(nNumIterations), null);

            Emgu.CV.Image<Bgr, Byte> cvimgUndistorted = UndistortBigImage<Bgra, Byte>(cvimgOutput).Convert<Bgr,Byte>();
            Emgu.CV.Image<Bgr, Byte> cvimgUndistortedColor = UndistortBigImage<Bgr, Byte>(cvimgColor);

            EraseDrawingBorders<Bgr,byte>(ref cvimgUndistorted);

            // Difference of gaussians math
            double grad1 = double.Parse(GW1Factor.Text) + 1.0;
            double gsigma1 = Math.Sqrt(-(grad1 * grad1) / (2 * Math.Log10(1.0 / 255.0)));
            double gsigmasq1 = 2 * gsigma1 * gsigma1;
            double gL1 = Math.Sqrt(-gsigmasq1 * Math.Log10(1.0 / 255.0));
            int n1 = (int)(Math.Ceiling(gL1) * 2.0) ;
            int gw1 = (n1%2==1) ? n1 : n1+1 ;

            double grad2 = double.Parse(GW2Factor.Text) + 1.0;
            double gsigma2 = Math.Sqrt(-(grad2 * grad2) / (2 * Math.Log10(1.0 / 255.0)));
            double gsigmasq2 = 2 * gsigma2 * gsigma2;
            double gL2 = Math.Sqrt(-gsigmasq2 * Math.Log10(1.0 / 255.0));
            int n2 = (int)(Math.Ceiling(gL2) * 2.0) ;
            int gw2 = (n2 % 2==1) ? n2 : n2 + 1;

            Emgu.CV.Image<Bgr, Byte> g1 = cvimgUndistorted.SmoothMedian(7).SmoothGaussian(gw1, gw1, gsigma1, gsigma1).Convert<Bgr, Byte>();
            Emgu.CV.Image<Bgr, Byte> g2 = cvimgUndistorted.SmoothMedian(7).SmoothGaussian(gw2, gw2, gsigma2, gsigma2).Convert<Bgr, Byte>();
            Emgu.CV.Image<Gray, Byte>[] thgArr = g1.Sub(g2).ThresholdBinary(new Bgr(0,0,0), new Bgr(255.0,255.0,255.0)).Split();
            Emgu.CV.Image<Gray, ushort> thg = (thgArr[0].Or(thgArr[1].Or(thgArr[2]))).Convert<Gray,ushort>().ThresholdBinary(new Gray(1), new Gray(65535));

            GenerateDetectMaskPolys(cvimgUndistorted.Size);

            Emgu.CV.Image<Gray, ushort> timg = DrawRectDetectMask<Gray,ushort>(ref thg);
            timg = thg.And(timg);

            float[] histIgnoreVals = new float[1] ;

            CalcEmptyPolys(ref thg, ref timg, ref histIgnoreVals);


            DisplayEmptyPolys<Gray, ushort>(ref timg, ref histIgnoreVals);

                
            //Emgu.CV.Image<Bgr, Byte> cvimgDewarped = cvimgUndistortedColor.WarpPerspective<double>(homographyMatrix
                //                                              , (int)(dLength * dScaleFactor)
                //                                            , (int)(dWidth * dScaleFactor)
                    //                                          , Inter.Cubic
                    //                                        , Warp.Default
                        //                                      , BorderType.Default
                        //                                    , new Bgr(0,0,0));

            Emgu.CV.Image<Bgr, Byte> cvimgDewarpedOrg = cvimgUndistorted
                                    .WarpPerspective<double>(homographyMatrix
                                                            , (int)(dLength * dScaleFactor)
                                                            , (int)(dWidth * dScaleFactor)
                                                            , Inter.Nearest // Inter.Cubic
                                                            , Warp.Default
                                                            , BorderType.Default
                                                            , new Bgr(0, 0, 0));

            Emgu.CV.Image<Bgr, Byte> cvimgDewarped = new Emgu.CV.Image<Bgr, Byte>(cvimgDewarpedOrg.Size);
            cvimgDewarpedOrg.CopyTo(cvimgDewarped);

            DisplayEmptyPolys<Bgr, Byte>(ref cvimgDewarpedOrg, ref histIgnoreVals, true);

            Emgu.CV.Image<Bgr, Byte> cvimgDewarpedSeg = new Emgu.CV.Image<Bgr, Byte>(cvimgDewarpedOrg.Size);
            cvimgDewarpedOrg.CopyTo(cvimgDewarpedSeg);


            Emgu.CV.Image<Bgr, Byte> cvimgDewarpedShaded = cvimgUndistortedColor
                                    .WarpPerspective<double>(homographyMatrix
                                                            , (int)(dLength * dScaleFactor)
                                                            , (int)(dWidth * dScaleFactor)
                                                            , Inter.Cubic
                                                            , Warp.Default
                                                            , BorderType.Default
                                                            , new Bgr(0, 0, 0));
            //DisplayEmptyPolys<Bgr, Byte>(ref cvimgDewarpedShaded, ref histIgnoreVals, true);

            Emgu.CV.Image<Gray, Byte> cvimgDewarpedThg = thg
                    .WarpPerspective<double>(homographyMatrix
                                            , (int)(dLength * dScaleFactor)
                                            , (int)(dWidth * dScaleFactor)
                                            , Inter.Cubic
                                            , Warp.Default
                                            , BorderType.Default
                                            , new Gray(0)).Convert<Gray,Byte>();


            //Emgu.CV.Image<Gray, Byte> cvimgBlobs = new Image<Gray, byte>(cvimgDewarpedShaded.Size);
            //DisplayEmptyPolys<Gray, Byte>(ref cvimgBlobs, ref histIgnoreVals, true);
            //MKeyPoint[] kp = GetBlobs<Gray, Byte>(cvimgBlobs);

            int nNumFills = 0;

            if (vecRackPolys.Size > 0)
            {
                System.Drawing.Point seedpt;
                System.Drawing.Point seedptd;

                System.Drawing.Size[] tl = new System.Drawing.Size[4]
                {
                    new System.Drawing.Size(-1,-1),
                    new System.Drawing.Size(1, -1),
                    new System.Drawing.Size(1, 1),
                    new System.Drawing.Size(-1, 1)
                };

                System.Drawing.Size tr = new System.Drawing.Size(1, -1);
                System.Drawing.Size br = new System.Drawing.Size(1, 1);
                System.Drawing.Size bl = new System.Drawing.Size(-1, 1);
                Rectangle rc = new Rectangle();

                System.Drawing.Size masksz = cvimgDewarpedOrg.Size + new System.Drawing.Size(2, 2);
                Emgu.CV.Image<Gray, Byte> mask = new Emgu.CV.Image<Gray, Byte>(masksz);

                int nFillToleranceLow = (int)float.Parse(FillToleranceLow.Text);
                int nFillToleranceHigh = (int)float.Parse(FillToleranceHigh.Text);

                for (int i=0; i<vecRackPolys.Size; i++)
                {
                    if (histIgnoreVals[i+1] == 0)
                    {
                        VectorOfPointF vpf = vecRackPolys[i];

                        for (int k=0; k<4; k++)
                        {
                            seedpt = Point.Round(vecRackPolys[i][k]);
                            seedptd = seedpt + tl[k];

                            // Is the point to be filled already white?  If so, ignore it.
                            byte Red_val = cvimgDewarpedOrg.Data[seedptd.Y, seedptd.X, 0];
                            byte Green_val = cvimgDewarpedOrg.Data[seedptd.Y, seedptd.X, 1];
                            byte Blue_val = cvimgDewarpedOrg.Data[seedptd.Y, seedptd.X, 2];

                            if (Red_val != 255 || Green_val != 255 || Blue_val != 255)
                            {
                                CvInvoke.FloodFill(cvimgDewarpedOrg
                                                    , mask
                                                    , seedptd
                                                    , new Bgr(255, 255, 255).MCvScalar
                                                    , out rc
                                                    , new Bgr(nFillToleranceLow, nFillToleranceLow, nFillToleranceLow).MCvScalar
                                                    , new Bgr(nFillToleranceHigh, nFillToleranceHigh, nFillToleranceHigh).MCvScalar
                                                    , Connectivity.EightConnected
                                                    , FloodFillType.FixedRange);
                                nNumFills++;
                            }
                        }
                    }
                }

                Emgu.CV.Image<Gray, byte> thresh = cvimgDewarpedOrg.ThresholdBinary(new Bgr(254, 254, 254), new Bgr(255, 255, 255)).Convert<Gray, byte>();
                /*
                using (VectorOfVectorOfPoint contours = new VectorOfVectorOfPoint())
                {
                    CvInvoke.FindContours(thresh, contours, null, RetrType.Ccomp, ChainApproxMethod.ChainApproxNone);
                    int count = contours.Size;
                    Emgu.CV.Util.VectorOfPoint approx = new VectorOfPoint();

                    for (int i = 0; i < count; i++)
                    {
                        if (contours[i] != null && (contours[i].Size > 150))
                        {
                            //int kk;
                            //RotatedRect rc = CvInvoke.MinAreaRect(contours[i]);
                            //System.Drawing.Point[] vertices = Array.ConvertAll(rc.GetVertices(), System.Drawing.Point.Round);
                            double epsilon = 0.01 * Emgu.CV.CvInvoke.ArcLength(contours[i], true);
                            Emgu.CV.CvInvoke.ApproxPolyDP(contours[i], approx, epsilon, true);

                            double dArea = Emgu.CV.CvInvoke.ContourArea(contours[i]);
                            Boolean bAreaIsConvex = Emgu.CV.CvInvoke.IsContourConvex(approx);

                            if (approx.Size == 4
                                && dArea > 40000
                                   )
                            {
                                RotatedRect rotrc = CvInvoke.MinAreaRect(contours[i]);
                                System.Drawing.Point[] vertices = Array.ConvertAll(rotrc.GetVertices(), System.Drawing.Point.Round);
                                CvInvoke.Polylines(cvimgDewarpedOrg
                                                    //, approx
                                                    , contours[i].ToArray()
                                                    //, vertices
                                                    , true
                                                    , new Bgr(0, 255, 0).MCvScalar
                                                    , 1
                                                        );

                                CvInvoke.Polylines(cvimgDewarpedOrg
                                                    //, approx
                                                    //, contours[i].ToArray()
                                                    , vertices
                                                    , true
                                                    , new Bgr(0, 255, 255).MCvScalar
                                                    , 5
                                                        );

                            }
                            else
                            if (dArea>40000)
                            {
                                CvInvoke.Polylines(cvimgDewarpedOrg
                                                    , contours[i].ToArray()
                                                    , true
                                                    , new Bgr(0, 0, 255).MCvScalar
                                                    , 1
                                                        );
                            }
                        }
                    }
                }*/

                int nImageIndex = int.Parse(ImageIndex.Text);

                // Draw on top of the dewarped thg a set of rectangles spaced by 2.629 inches, 0.75 inchs wide
                RectangleF rectangleF = new RectangleF(new PointF(1F*dScaleFactorF, 11F*dScaleFactorF), new SizeF(1F * dScaleFactorF, 63.125F * dScaleFactorF));
                Rectangle rectangle = Rectangle.Round(rectangleF); 
                Emgu.CV.Image<Bgr,Byte> cvimgTestColumns = new Image<Bgr,Byte>(cvimgDewarpedThg.Size);


                do
                {
                    Point[] pts = new Point[4];
                    pts[0] = rectangle.Location;
                    pts[1] = pts[0] + new System.Drawing.Size(rectangle.Width, 0);
                    pts[2] = pts[1] + new System.Drawing.Size(0,rectangle.Height);
                    pts[3] = pts[2] + new System.Drawing.Size(-rectangle.Width, 0);

                    cvimgTestColumns.FillConvexPoly(pts, new Bgr(0, 0, 160));
                    cvimgTestColumns.Draw(rectangle, new Bgr(0, 0, 255), 1);

                    rectangleF.Offset(2.629F * dScaleFactorF, 0F);
                    rectangle = Rectangle.Round(rectangleF);
                } while (rectangle.Left < cvimgDewarpedThg.Width);


                Emgu.CV.Image<Gray,Byte> threshDilateErode = thresh.Dilate(10).Erode(10);

                // threshDilateErode now contains the contours we want to search through.
                using (VectorOfVectorOfPoint contours = new VectorOfVectorOfPoint())
                {
                    CvInvoke.FindContours(threshDilateErode, contours, null, RetrType.Ccomp, ChainApproxMethod.ChainApproxNone);
                    int count = contours.Size;
                    Emgu.CV.Util.VectorOfPoint approx = new VectorOfPoint();

                    for (int i = 0; i < count; i++)
                    {
                        if (contours[i] != null && (contours[i].Size > 150))
                        {
                            //int kk;
                            //RotatedRect rc = CvInvoke.MinAreaRect(contours[i]);
                            //System.Drawing.Point[] vertices = Array.ConvertAll(rc.GetVertices(), System.Drawing.Point.Round);
                            double epsilon = 0.05 * Emgu.CV.CvInvoke.ArcLength(contours[i], true);
                            Emgu.CV.CvInvoke.ApproxPolyDP(contours[i], approx, epsilon, true);

                            double dArea = Emgu.CV.CvInvoke.ContourArea(contours[i]);
                            Boolean bAreaIsConvex = Emgu.CV.CvInvoke.IsContourConvex(approx);

                            if (approx.Size == 4
                                && dArea > 40000
                                   )
                            {
                                System.Drawing.Point center;
                                System.Drawing.Size size;
                                string tstr;
                                int nBaseLine;

                                RotatedRect rotrc = CvInvoke.MinAreaRect(contours[i]);
                                System.Drawing.Point[] vertices = Array.ConvertAll(rotrc.GetVertices(), System.Drawing.Point.Round);
                                CvInvoke.Polylines(cvimgDewarpedOrg
                                                    //, approx
                                                    , contours[i].ToArray()
                                                    //, vertices
                                                    , true
                                                    , new Bgr(0, 255, 0).MCvScalar
                                                    , 1
                                                        );

                                CvInvoke.Polylines(cvimgDewarpedOrg
                                                    //, approx
                                                    //, contours[i].ToArray()
                                                    , vertices
                                                    , true
                                                    , new Bgr(0, 255, 255).MCvScalar
                                                    , 5
                                                        );

                                List<Point> plist = new List<Point>();
                                plist.AddRange(contours[i].ToArray());

                                // First, sort by y, and create a list of widths
                                var psortedlist = plist.OrderBy(p => p.Y).ThenBy(p => p.X);

                                dMedianHeightF = dMedianWidthF = 0F;

                                int nelem = psortedlist.Count();
                                if (nelem > 0)
                                {
                                    List<int> widths = new List<int>();
                                    int nCurX = psortedlist.ElementAt(0).X;
                                    int nCurY = psortedlist.ElementAt(0).Y;
                                    int nFirstX = nCurX;
                                    int nWidth = 0;

                                    foreach (Point p in psortedlist)
                                    {
                                        if (nCurY != p.Y)
                                        {
                                            // are we on a new line?
                                            widths.Add(nCurX - nFirstX);
                                            nCurY = p.Y;
                                            nCurX = p.X;
                                            nFirstX = nCurX;
                                        }
                                        else
                                            nCurX = p.X;
                                    }
                                    widths.Add(nCurX - nFirstX);
                                    
                                    widths.Sort();

                                    int nMedianWidth = widths.ElementAt(widths.Count()/2);
                                    dMedianWidthF = (float)nMedianWidth / dScaleFactorF;
                                }


                                // Then, sort by x, and create a list of heights
                                psortedlist = plist.OrderBy(p => p.X).ThenBy(p => p.Y);

                                nelem = psortedlist.Count();
                                if (nelem > 0)
                                {
                                    List<int> heights = new List<int>();
                                    int nCurX = psortedlist.ElementAt(0).X;
                                    int nCurY = psortedlist.ElementAt(0).Y;
                                    int nFirstY = nCurY;

                                    foreach (Point p in psortedlist)
                                    {
                                        if (nCurX != p.X)
                                        {
                                            // are we on a new line?
                                            heights.Add(nCurY - nFirstY);
                                            nCurY = p.Y;
                                            nCurX = p.X;
                                            nFirstY = nCurY;
                                        }
                                        else
                                            nCurY = p.Y;
                                    }
                                    heights.Add(nCurY - nFirstY);

                                    heights.Sort();

                                    int nMedianHeight = heights.ElementAt(heights.Count() / 2);
                                    dMedianHeightF = (float)nMedianHeight / dScaleFactorF;
                                }

                                center = approx[0];
                                center.Offset(approx[1]);
                                center.Offset(approx[2]);
                                center.Offset(approx[3]);
                                center.X /= 4;
                                center.Y /= 4;

                                tstr = "W=" + dMedianWidthF.ToString("0.00") + "\nH=" + dMedianHeightF.ToString("0.00");

                                nBaseLine = 0;
                                System.Drawing.Size sz = Emgu.CV.CvInvoke.GetTextSize(tstr.Split("\n", 2)[0], FontFace.HersheyPlain, 6, 3, ref nBaseLine);
                                size = new System.Drawing.Size() - sz;
                                size.Width /= 2;

                                foreach (string sstr in tstr.Split("\n", 2))
                                {
                                    Emgu.CV.CvInvoke.PutText(cvimgDewarpedOrg, sstr, center + size, FontFace.HersheyPlain, 6, new MCvScalar(0, 0, 0), 3);
                                    center.Y += 100;
                                }

                            }
                            else
                            if (dArea > 40000)
                            {
                                CvInvoke.Polylines(cvimgDewarpedOrg
                                                    , contours[i].ToArray()
                                                    , true
                                                    , new Bgr(0, 0, 255).MCvScalar
                                                    , 1
                                                        );
                            }
                        }
                    }


                    Title =   "MainWindow - Undistort Done - " 
                            + System.IO.Path.GetFileName(szLastFileName) 
                            + "  Contour Count=" + contours.Size.ToString();
                }




                switch (nImageIndex)
                {
                    case 0: gdiImage.Source = ToBitmapSource(cvimgDewarpedShaded); gdiGreyImage.Source = ToBitmapSource(cvimgDewarped); break;
                    case 1: gdiImage.Source = ToBitmapSource(thresh); gdiGreyImage.Source = ToBitmapSource(cvimgDewarpedOrg); break;
                    case 2: gdiImage.Source = ToBitmapSource(cudaImageOut.ToMat()); gdiGreyImage.Source = ToBitmapSource(cvimgDewarpedOrg); break;
                    case 3: gdiImage.Source = ToBitmapSource(thg); gdiGreyImage.Source = ToBitmapSource(cvimgUndistortedColor); break;
                    case 4: gdiImage.Source = ToBitmapSource(cvimgUndistorted); gdiGreyImage.Source = ToBitmapSource(cvimgDewarpedOrg); break;
                    case 5: gdiImage.Source = ToBitmapSource(cvimgDewarpedThg); gdiGreyImage.Source = ToBitmapSource(cvimgDewarpedOrg); break;
                    case 6: gdiImage.Source = ToBitmapSource(cvimgDewarpedSeg); gdiGreyImage.Source = ToBitmapSource(cvimgDewarpedOrg); break;
                    case 7: gdiImage.Source = ToBitmapSource(cvimgTestColumns); gdiGreyImage.Source = ToBitmapSource(cvimgDewarpedOrg); break;
                    case 8: gdiImage.Source = ToBitmapSource(threshDilateErode); gdiGreyImage.Source = ToBitmapSource(thresh); break;
                    case 9: gdiImage.Source = ToBitmapSource(threshDilateErode); gdiGreyImage.Source = ToBitmapSource(cvimgDewarpedOrg); break;
                }
                //gdiImage.Source = ToBitmapSource(cudaImageOut.ToMat());
            }
        }

        private MKeyPoint[] GetBlobs<TColor,TDepth>(Emgu.CV.Image<TColor,TDepth> img)
            where TColor : struct, Emgu.CV.IColor
            where TDepth : new()
        {
            SimpleBlobDetectorParams detectorParams = new SimpleBlobDetectorParams
            {
                //MinDistBetweenBlobs = 10, // 10 pixels between blobs
                //MinRepeatability = 1,

                //MinThreshold = 100,
                //MaxThreshold = 255,
                //ThresholdStep = 5,

                FilterByArea = false,
                //FilterByArea = true,
                //MinArea = 0.001f, // 10 pixels squared
                //MaxArea = 500,

                FilterByCircularity = false,
                //FilterByCircularity = true,
                //MinCircularity = 0.001f,

                FilterByConvexity = false,
                //FilterByConvexity = true,
                //MinConvexity = 0.001f,
                //MaxConvexity = 10,

                FilterByInertia = false,
                //FilterByInertia = true,
                //MinInertiaRatio = 0.001f,

                //FilterByColor = false
                FilterByColor = true,
                blobColor = 255 // to extract light blobs
            };
            SimpleBlobDetector simpleBlobDetector = new SimpleBlobDetector(detectorParams);
            MKeyPoint[] keyPoints = simpleBlobDetector.Detect(img);

            return keyPoints;
        }


        private void testButton_Click(object sender, RoutedEventArgs e)
        {
            LoadCalibrationImages();
        }

        private void testButton2_Click(object sender, RoutedEventArgs e)
        {
            DetectCorners();
        }

        private void testButton3_Click(object sender, RoutedEventArgs e)
        {
            SaveCornerDetectImage();
        }

        private void UndistortImageClick(object sender, RoutedEventArgs e)
        {
            DetectEdges(true);
        }

        private void RedoClick(object sender, RoutedEventArgs e)
        {
            DetectEdges(false);
        }

    }
}
